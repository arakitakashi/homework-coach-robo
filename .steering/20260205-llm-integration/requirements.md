# Requirements - LLM統合

## 背景・目的

ソクラテス式対話エンジンの基盤（データモデル、対話マネージャ、APIエンドポイント）は実装済みだが、
現在はテンプレートベースの応答を返している。実際のLLM（Google Gemini API）を統合し、
以下の機能を動的に生成できるようにする：

1. **回答分析**: 子供の回答を分析し、理解度・方向性を判定
2. **質問生成**: ソクラテス式の誘導質問を生成
3. **ヒント生成**: 3段階ヒントシステムに応じたヒントを生成

## 要求事項

### 機能要件

| ID | 要件 | 優先度 |
|----|------|--------|
| FR-01 | Gemini APIを使用して子供の回答を分析できる | 必須 |
| FR-02 | Gemini APIを使用して誘導質問を生成できる | 必須 |
| FR-03 | Gemini APIを使用してヒントレベル別の応答を生成できる | 必須 |
| FR-04 | LLMクライアントが未設定の場合、フォールバック応答を返す | 必須 |
| FR-05 | APIキーは環境変数から取得する | 必須 |

### 非機能要件

| ID | 要件 | 目標値 |
|----|------|--------|
| NFR-01 | LLM応答のレイテンシ | 3秒以内（目標2秒） |
| NFR-02 | テストカバレッジ | 80%以上 |
| NFR-03 | エラーハンドリング | LLMエラー時にフォールバック |

### 制約条件

1. **既存インターフェースの維持**: `LLMClient`プロトコルに準拠
2. **非同期対応**: FastAPIとの統合のため非同期（async/await）必須
3. **依存関係**: `google-genai` パッケージを使用（pyproject.tomlに追加済み）
4. **環境変数**: `GOOGLE_API_KEY` または `GEMINI_API_KEY` から取得

## 対象範囲

### In Scope

- `GeminiClient` クラスの実装（`LLMClient`プロトコル準拠）
- `SocraticDialogueManager` へのLLMクライアント注入
- APIエンドポイントでのLLMクライアント使用
- 環境変数からのAPIキー取得
- エラーハンドリングとフォールバック

### Out of Scope

- 音声入出力（Gemini Live API）- 別フェーズで対応
- セッションの永続化（Redis/Firestore）- 別フェーズで対応
- WebSocketリアルタイム通信 - 別フェーズで対応
- 感情認識・適応ロジック - 別フェーズで対応

## 成功基準

1. [ ] `GeminiClient` が `LLMClient` プロトコルに準拠している
2. [ ] 回答分析APIが実際のLLM応答を返す
3. [ ] 質問生成APIが実際のLLM応答を返す
4. [ ] ヒント生成APIが実際のLLM応答を返す
5. [ ] APIキー未設定時に適切なエラーメッセージを返す
6. [ ] テストカバレッジ80%以上を維持
7. [ ] 全テストがパスする
